{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\abdo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import nltk \n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filenmae):\n",
    "    data=pd.read_csv(filenmae,sep='\\t')\n",
    "    data['tags']=data['tags'].apply(literal_eval)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=read_data('data/train.tsv')\n",
    "validation=read_data('data/validation.tsv')\n",
    "test=pd.read_csv('data/test.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "stop_words=set(stopwords.words('english'))\n",
    "table = str.maketrans('','',punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textclean(text):\n",
    "    tokens=word_tokenize(text)\n",
    "    tokens=[word for word in tokens if word.isalpha()]\n",
    "    tokens=[w.translate(table) for w in tokens]\n",
    "    tokens=[word for word in tokens if not word in stop_words]\n",
    "    token = [word for word in tokens if len(word)>1 ]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_train=[]\n",
    "contents_validation=[]\n",
    "for index,row in train.iterrows():\n",
    "    text=row['title'].lower()\n",
    "    contents_train.append(textclean(text))\n",
    "    \n",
    "for index,row in validation.iterrows():\n",
    "    text=row['title'].lower()\n",
    "    contents_validation.append(textclean(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "D:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "n_dim=200\n",
    "\n",
    "w2v_model_train =Word2Vec(contents_train,min_count=5,size=n_dim)\n",
    "w2v_model_validation =Word2Vec(contents_validation,min_count=5,size=n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "#vectorizer  = TfidfVectorizer(min_df=10,analyzer=lambda x: x)\n",
    "\n",
    "#matrix=vectorizer.fit_transform(contents)\n",
    "#tfidf = dict(zip(vectorizer.get_feature_names(),vectorizer.idf_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "def create_word_vector(l,size,flag):\n",
    "    vector = np.zeros(size).reshape((1,size))\n",
    "    count = 0.\n",
    "    for word in l:\n",
    "        try:\n",
    "            if flag == 'train':\n",
    "                vector += w2v_model_train[word].reshape((1, size)) \n",
    "                count+=1\n",
    "            else:\n",
    "                vector += w2v_model_validation[word].reshape((1, size)) \n",
    "                count+=1\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "    if count!=0:\n",
    "        vector /= count\n",
    "    return vector\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_validation = []\n",
    "y_validation = []\n",
    "for i in range(len(train)):\n",
    "    converted_review = create_word_vector(contents_train[i],n_dim,'train')\n",
    "    #print(converted_review)\n",
    "    X_train.append(np.array(converted_review))\n",
    "    y_train.append(train['tags'][i]) \n",
    "for i in range(len(validation)):\n",
    "    converted_review = create_word_vector(contents_validation[i],n_dim,'validation')\n",
    "    #print(converted_review)\n",
    "    X_validation.append(np.array(converted_review))\n",
    "    y_validation.append(validation['tags'][i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "X_train = scale(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "X_validation = np.concatenate(X_validation)\n",
    "X_validation = scale(X_validation)\n",
    "y_validation = np.array(y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 200)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "tags_counts=Counter([item for taglist in y_train for item in taglist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=sorted(tags_counts.keys()))\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_validation = mlb.fit_transform(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "clf = OneVsRestClassifier(SVC())\n",
    "clf = clf.fit(X_train,y_train)\n",
    "............++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predicted = clf.predict(X_validation)\n",
    "y_val_predicted = clf.decision_function(X_validation)\n",
    "\n",
    "y_val_pred_inversed = mlb.inverse_transform(y_val_predicted)\n",
    "y_val_inversed = mlb.inverse_transform(y_validation)\n",
    "for i in range(3):\n",
    "    print('Title:\\t{}\\nTrue labels:\\t{}\\nPredicted labels:\\t{}\\n\\n'.format(\n",
    "        validation[i],\n",
    "        ','.join(y_val_inversed[i]),\n",
    "        ','.join(y_val_pred_inversed[i])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "def print_evaluation_scores(y_val, predicted):\n",
    "    \n",
    "    ######################################\n",
    "    ######### YOUR CODE HERE #############\n",
    "    ######################################\n",
    "    print (\"Accracy={}\".format(accuracy_score(y_val, predicted)), \n",
    "        \"\\n\\nF1_macro={}\".format(f1_score(y_val, predicted, average='macro')),\n",
    "        \"\\n\\nF1_micro={}\".format(f1_score(y_val, predicted, average='micro')),\n",
    "        \"\\n\\nF1_wted={}\".format(f1_score(y_val, predicted, average='weighted')),\n",
    "        \"\\n\\nPrecsion_macro={}\".format(average_precision_score(y_val, predicted, average='macro')),\n",
    "        \"\\n\\nPrecsion_micro={}\".format(average_precision_score(y_val, predicted, average='micro')),\n",
    "        \"\\n\\nPrecsion_wted={}\".format(average_precision_score(y_val, predicted, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_evaluation_scores(y_validation, y_val_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
